\documentclass[12pt, titlepage]{article} 

\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{colonequals}
\usepackage[hyphens]{url}

% Multi-row columns in a table
\usepackage{multirow}

% derivations
\usepackage{semantic}

% code
\usepackage{listings}
\usepackage{color}

% code definitions
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true
  tabsize=2
}

\title{Pratical Types for Python \\ Final Report}
\author{Daniel Randall}
\date{}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introduction}
\subsection{Motivation}
High level, dynamically typed languages such as Python have been gaining popularity in recent years. Python is used as a teaching language in 80\% of the top ten Computer Science department in the USA, surpassing previous favourites such as Java~\cite{guoTeaching}. Python has also become a force in industry and has been picked up by important software engineering companies such as Google and Yahoo!~\cite{organisationsPython}. One reason for this is a high level of productivity involved in using such languages, partly due to the programmer being free from having to declare the types of the variables used. However, the benefits gained from this design decision are at the expense of the security provided by a statically typed language. Type errors which are easily caught by a compiler for a statically typed language, such as Java or C++, can be left unnoticed in Python source code into the release stage of a product where its execution may prove fatal. % Specifying types is regarded as superfluous by many in the Python community.
While there has been significant talk of adding optional static typing to Python~\cite{guido1}~\cite{guido2}~\cite{guido3}, the backlash from such discussions is strong enough that it is very unlikely we shall see this addition to the Python language anytime soon. \\
Tools attempting to provide the benefits of a statically typed language to Python do exist, such as Pylint\footnote{\url{http://www.pylint.org/}} and PyChecker\footnote{\url{http://pychecker.sourceforge.net/}}, however their usability is hampered by the number of false positives returned and the amount of configuration needed. \\
This project aims to design and implement a type checker for Python which returns no false positives. The basis for our implementation is a method called success typings. We harness this technique in order to provide a over-approximation of how a function is intended to be used. This allows us to determine that a violation of a function's contract is guaranteed to be a legitimate programming error. We describe success typing as well as the general theory behind type systems in Section 2. We then examine similar products and techniques and show the limitations in their application. \\
\indent Using the methods and techniques we described, we begin to define our solution and evaluate the best way to solve the problems we shall face. Once we decide upon the best methods we then set about evaluating the best 3\textsuperscript{rd} party software we can use to achieve these tasks and why we should not implement our own solutions. \\
\indent In Section 3 we describe what we have done and evaluate it. We evaluate our implementation in three ways: speed, ease of use and the number of false positives/negatives it reports. We benchmark our solution against existing type checkers for Python.

\subsection{Objectives}
The objectives for this project are as follows:
\begin{itemize}
	\item \textbf{A low number of false positives} - Our solution should report a minimal number of errors which are then found not to be genuine bugs in the program. A `genuine' bug can be defined as one which is guaranteed to cause an un-caught run-time exception when executed.
	\item \textbf{Static} - Our solution should not require the user to run the program.
	\item \textbf{Out-of-the-box} - The user should not need to specify the way in which the tool should run, such as command line arguments. The user also should not have to modify their program in any way in order to successfully use our solution.
	\item \textbf{Fast} - Our system will ideally run at a high speed, similar to other type checkers for Python.
\end{itemize} 

\newpage
\section{Types in Programming Languages}
Type systems are created by the developers of programming languages to prevent improper use of program operations. To quote Benjamin Pierce~\cite{pierce02}:
\begin{quote}
	\emph{``A type system is a tractable syntactic method for proving the absence of certain program behaviors by classifying phrases according to the kinds of values they compute.''}
\end{quote}
In order for this to hold in programming languages, the phrases (e.g.\ variables, expressions, method calls) are labelled to express the classification. This labelling can be achieved in a number of ways and allows the language to prevent operations from being used with terms with a classification that they were not designed to be used with. \\
A type system can used for detecting errors, documentation, language safety, abstraction and efficiency~\cite{pierce02}. This report focuses on error detection.

\subsection{Static and Dynamic Type Systems}
Static type systems require programs to be written such that all variables are labelled with a type. Static type systems are conservative, meaning that they can reject programs which may never cause an error at run-time. Consider the following example for the statically typed C++ language:
\begin{lstlisting}
	if (true) {	
	  int x = 5;
	} else {
	  int x = 5 + "Hello world";
	}
\end{lstlisting}
The C++ compiler will not accept this code despite the fact that it will, intuitively, behave well at run-time. This is because the type system is able to determine the \textit{absence} of type errors, that is it can determine whether code can possibly type error. However, it can not detect the \textit{presence} of type errors, that is whether code which could type error will ever be executed at all or in such a way that it will ever type error. \\
Dynamic type systems do not require types for variables until run-time where ``run-time type tags are used to distinguish different kinds of structures in the heap.''~\cite{pierce02} Dynamic type systems do not suffer from the same conservative nature as statically typed languages. For instance, the equivalent program to the previous C++ example in Python is:
\begin{lstlisting}
	if (True):	
	  x = 5;
	else:
	  x = 5 + "Hello world"
\end{lstlisting}
This program will never raise a type error, despite the fact $5 + ``Hello  world"$ is an illegal operation. Using a dynamic type system, only programs about to go wrong during run-time are rejected. The obvious downside to this is that errors which would be caught easily by a static type system may go undetected by a dynamic type system and wreak havoc later in the production cycle. As a trivial example of this, consider the following snippet of Python code is a small part of a large program. This program allows a user to heal their characters using potions. The designer has decided that the health of a character should be within a wrapper class and a function \textit{add\_health} is used to combine health points:
\begin{lstlisting}
	def add_health(character, healer):
	  character.hp += healer.health_gain	

	def heal(character, potion):
	  if potion == normal_potion:
	    add_health(character, potion)
	    return
	  if potion == special_potion:
	    calculate_health_gain(potion)
	    character.hp += potion		
	    return
\end{lstlisting}
With all the extra code the programmer had to write for the `special potion' they forgot to use the \textit{add\_health} function! The types of \textit{character\_health} and \textit{potion} are incompatible together with the \textit{+=} operator and a type error will be raised if this branch is executed. If the programmer also neglects to include this special potion in their test suite then this code may be shipped without this branch ever been executed.

\subsection{Abstract Syntax Tree}
An abstract syntax tree (AST) ``represents the hierarchical syntactic structure of the source 
program''~\cite{dragonBook} in a tree data structure where ``each 
interior node represents an operator; the children of the node represent the 
operands of the operator.''~\cite{dragonBook} \\
An AST provides us with the means of reasoning about the source code. Instead of having to parse a single large string to find what what we need we can search through and manipulate the tree data structure. \\
Python provides the built-in \textit{ast} module which generates an AST from Python source code. The ast module transforms the following module:
\begin{lstlisting}
    x = 4
    if x == 4:
      x = 5.0 + 1
    else:
      x = "Hi"
      print(x)
\end{lstlisting}
into the following AST:
\begin{verbatim}
Module(body=[
    Assign(targets=[Name(id='x',ctx=Store())],
                              value=Num(n=4))
    If(
      test=Compare(left=Name(id='x',ctx=Load()),
                   ops=[Eq()],comparators=[Num(n=4)])
      body=[Assign(targets=[Name(id='x',ctx=Store())],
                   value=BinOp(left=Num(n=5.0),op=Add(),
                               right=Num(n=1)))]
      orelse=[Assign(targets=[Name(id='x',ctx=Store())],
                     value=Str(s='Hi'))])
    Expr(value=Call(func=Name(id='print',ctx=Load()),
                        args=[Name(id='x',ctx=Load())]))])
\end{verbatim}
As far as we can tell, no other library has been written which generates ASTs from Python source code.

\subsection{Control Flow}
The control flow of an application is the route taken when the program is executed or the order in which individual statements are executed. Consider the following program:
\begin{lstlisting}
	1. x = 5
	2. x = x + 1
	3. print(x)
\end{lstlisting}
The route taken by this program is simply $1 \rightarrow 2 \rightarrow 3$. However with the introduction of conditional statements such as \textit{if}, \textit{for} and \textit{while} the path taken in the program is dynamically decided by the evaluation of a condition. While the introduction of these statements undoubtedly provide more power to an engineer, it becomes far more difficult to statically predict the route taken. An example of this is as follows:
\begin{lstlisting}[mathescape]
	1. if ($p_1$):
	2. 	x = 5
	3. else:
	4. 	x = 5.0
	5. print(x)
\end{lstlisting}
The flow of the above program can be described as $1 \rightarrow (2, 4) \rightarrow 5$ where $(x, y)$ represents a choice between $x$ and $y$.

\subsubsection{Control Flow Graph}
A control flow graph (CFG) is a way of depicting the control flow of a program. A CFG provides a graphical way of representing the control flow as well as providing a meaningful way of storing this information in a program. CFGs are commonly used in compilers in order to reduce program size and increase performance by eliminating dead code. \\
CFGs introduce the concept of a \textit{basic block} which consists of only straight line code and no branching statements such as ifs and loops. ``The nodes of the flow 
graph are the basic blocks. There is an edge from block B to block C if and 
only if it is possible for the first instruction in block C to immediately follow 
the last instruction in block B.''~\cite{dragonBook} Control flow statements introduce new basic blocks for each branch created by them. For example, an if statement creates two basic blocks, one for the then body and one for the else body. The basic blocks are then linked using directed links with each block pointed towards its successors. \\
Using the last example of \textit{if} statement in the previous section we get:
\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{images/controlFlowGraph.pdf}
\end{figure}  \\
Since the primary use for CFGs in computing is for compilers it is natural that a good place to find a CFG generator in Python is in a Python compiler. The most commonly used interpreter for Python code is \textit{CPython}. CPython uses CFGs~\cite{cpythonCFG, but is written in C, making it necessary to go through the cumbersome process of converting C data structures into equivalent Python data structures. As well as this, the CPython process of generating a CFG is to rely on generated bytecode to determine how a program branches. Due to this a iterable CFG is never generated. \\
\textit{PyPy}, an alternative interpreter for Python, also uses CFG generation in its tool-chain~\cite{pypyCFG}. Unlike CPython, PyPy is written in Python, however its design is very similar to that of CPython meaning it also depends on a bytecode interpreter to generate its CFGs. \\
In 2013 a student named Ashwin Panchapakesan from the University of Ottawa built a tool to generated CFGs from Python source code~\cite{ashwinCFG}. To do this the program parses an AST created from the Python code into XML. The XML uses tags to indicate the type of a statement, such as if, while or expression. Within these tags is the line number of the statement. An example of this XML is as follows:
\begin{verbatim}
<?xml version="1.0" ?>
<module>
    0
    <functiondef>
        24
        <expr>
            26
            <call>
                26
                <str>26</str>
                <if>
                    12
                    <call>12</call>
                    <return>13</return>
                </if>
                <return>16</return>
            </call>
        </expr>
    </functiondef>
</module>
\end{verbatim}
The XML format of the program is then analysed in order to determine where each line number is able to flow to. The CFG generated is easy to extract from this program, however the only information contained in this XML are the line numbers making it difficult to work with. While we could just extract the matching lines of raw source code, we would then need to break down the Python syntax ourselves to extract the information to analyse. There is also now way cheap way to extract the necessary information from the AST based on the line numbers.

\subsubsection{Flow-sensitivity}
A flow insensitive analysis of a program does not consider the order of execution~\cite{nielson99}. That is, each occurrence of a variable typically is represented by the same set of possible types no matter where it appears in the program. Consider the following example:
\begin{lstlisting}
	if (y):	
	  x = 5     # S1
	else:
          x = 5.0        # S2
	f(x)		    # S3
\end{lstlisting}
A flow-sensitive algorithm would infer the type of $x$ at S1 to be $\left\{ {int}\right\}$ and $\left\{ {float}\right\}$ at S2, while a flow-insensitive algorithm would infer the type of $x$ to be $\left\{ {int, float}\right\}$ at S1, S2 and S3. \\
Another case in which ignoring the flow of execution can change the types inferred is represented by the following trivial block of code:
\begin{lstlisting}
	x = 5
	x = 5.0
\end{lstlisting}
A flow-insensitive algorithm would infer the type of \textit{x}, for any future occurrences of $x$, to be in the set $\left\{ {int, float}\right\}$. A flow-sensitive algorithm is able to recognise that the second statement `overwrites' the first. This permits a more accurate representation of the flow, allowing it to infer more accurately the type of $x$ as the set $\left\{ {float}\right\}$. \\
A flow-sensitive algorithm is clearly the more accurate approach but requires a comparatively complex algorithm which consumes more information than a flow-insensitive approach. \\
Ryder~\cite{ryder03} suggests that the difference between a flow-sensitive and flow-insensitive approach is minimal in regards to object-oriented programs due to the size of methods being small. While Python can be, and is, used for object-oriented programming, a significant number of Python programs are written as scripts and so the benefits of a flow-sensitive algorithm can not ruled out in our case.

\subsection{SSA Naming}
Primarily used in compilers, Single Static Assignment (SSA) is used to acquire ``unique names for distinct entities.''~\cite{ssaBook} What this means is that each variable should only be assigned to once. There are number of variants of SSA, each designed for a specialised purpose, such as Hashed SSA form which intends to capture the fact that a single static use or definition (e.g.\ $*p$ in C) could potentially impact multiple variables. In our case we are only to use a basic version of SSA, `vanilla' SSA which we will now describe. \\
Consider the following example:
\begin{lstlisting}
	x = 5
	y = x + 1
	x = 7
	z = x + 1
\end{lstlisting}
This code violates the SSA requirements since the variable $x$ is assigned to twice. Translating this block into SSA form would give us the following:
\begin{lstlisting}
	x1 = 5
	y1 = x1 + 1
	x2 = 7
	z1 = x2 + 1
\end{lstlisting}
It can be observed that the latest assignment of $x$  is used in all instances of $x$ where $x$ isn't being assigned a new value. This can be seen in the assignments to $y$ and $z$ where $x_1$ and $x_2$ is used respectively. \\
Note that the names of, both, $y$ and $z$ need not be changed in this case since they are only assigned to once. However it often makes the implementation of SSA easier to do so regardless.

\subsubsection{The $\phi$ function}
In a sequential program the manner used to number new variables is quite intuitive, we simply increment the number appended the end of the variable name. However as we introduce branching into our programs this method alone breaks down. Consider the following program:
\begin{lstlisting}
	x = 5
	if (y):
	  x = 5
	else:
	  x = 6
	z = x + 1
\end{lstlisting}
The \textit{if} statement has two branches which both assign a new value to the variable $x$. Assigning new names to these variables is required by the rules of SSA, however it is unclear which name we are to use after the \textit{if} and \textit{else} when \textit{x} is used in then assignment to the variable \textit{z}. \\
To resolve this problem, we introduce the concept of the \emph{$\phi$ function}. The $\phi$ function is used ``to merge values from different incoming paths, at control-flow merge points.''~\cite{ssaBook} Put simply, the result of the $\phi$ can be said to be \emph{any} of the parameters given. 
\begin{lstlisting}[mathescape]
	x1 = 5
	if (y):
	  x2 = 5.0
	else:
	  x3 = 6
	x4 = $\phi$(x2, x3)
	z = x + 1
\end{lstlisting}
Since we only care about the possible types of each variable the $\phi$ function can viewed as a glorified union of all possible types of all parameters in our case. So in the above example we would have $x4 = \phi(x2, x3) = \{Float\} \cup \{Int\} = \{Float, Int\}$. \\
A similar, slightly more complex case arises for loops. In this case, we must consider the types of the variables at each iteration of the loop as well as the exit. Consider the following trivial example:
\begin{lstlisting}
	x = 5
	while (y):
	  x = x + 1.0
	z = x + 1
\end{lstlisting}
At the entry of the loop, $x$ can come from the statement immediately before the loop as well as the end of the loop. The case for immediately outside the loop is the same as the case for \textit{if}. This can be seen clearly in Figure~\ref{phiCFG} where there are two entries into the loop header where $x$ may take a value. Using this information gives us two causes for a $\phi$ function. The resulting program in SSA form is:


\begin{lstlisting}[mathescape]
	x1 = 5
	while (y):
	  x2 = $\phi$(x1, x3)
	  x3 = x2 + 1.0
	x4 = $\phi$(x1, x3)
	z = x4 + 1
\end{lstlisting}
The $\phi$ function can also be used for inferring the possible return types of a function. Consider the following Python function:
\begin{lstlisting}[mathescape]
	def f():
		if ($p_1$):
		  return 5
		if ($p_2$):
		  return "Hi"
		return 5.0
\end{lstlisting}
Here we can see that the function \textit{f} has a number of different \textit{return} statements which can return a number of different types. In order to infer the possible types that a function can return we need to look at the types of each return statements. We can use the $\phi$ function in order to simplify this task. To do so we modify the function as follows:
\begin{lstlisting}[mathescape]
	def f():
		if ($p_1$):
		  $r_1$ = 5
		if ($p_2$):
		  $r_2$ = "Hi"
		$r_3$ = 5.0
		$r_4$ = $\phi$($r_1$, $r_2$, $r_3$)
\end{lstlisting}

The usefulness of SSA naming is immediately obvious. We need not track how the types of a variable may change over time. We may treat each new naming as a completely distinct variable. Managing the control-flow also becomes a much simpler task as we are easily able to express the fact that a variable can possibly be a number of different types depending on the path taken through the program.

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{images/ssaPhiNode.pdf}
\caption{while loop as a CFG}
\label{phiCFG}
\end{figure}

\subsection{Dead Code Elimination}
Dead Code Elimination, also known as Tree Shaking, is the process of detecting that a section of code is dead (unreachable) and completely eliminating it from the program. Code may be unreachable if it is placed after a \textit{break}, \textit{continue} or \textit{return} statement or if the code has the effect of only modifying variables which will never be used again (`dead' variables.) The advantages of this is that we need not type check it, thus improving the speed of our program.
An example of this is: (adapted from Wikipedia)
\begin{lstlisting}
   def foo ():
   	a = 24
   	b = 25    # Assignment to dead variable
   	c = a + 2
   	return c
   	b = 24 	   # Unreachable code
   	return 0
\end{lstlisting}
Whether flagging an error on unreachable code constitutes a false-positive is one for the philosophers. \\
Unfortunately there are no out-of-the-box solutions to this problem for Python programs. \\

\subsection{Constraints and Constraint Solvers}
``A constraint satisfaction problem [CSP] is a problem where one has to finda  value for a (finite) set of variables satisfying a (finite) set of constraints.''~\cite{constraintBook} A CSP is typically described using the following notation: $\langle X, D, C \rangle$. Where $X$ represents a set of variables, $D$ is a set of corresponding domains and $C$ is a set of constraints that any solution must satisfy. Every variable must have a \textit{domain}. A domain specifies the values a variable can take. An example domain is the set of integers, $\mathbb{Z}$. A solution to a CSP is a mapping from the given variables to a value in the domain which satisfies the constraints provided. \\
An example of a CSP is the following, where each letter must be replaced with a different number such that the sum evaluates correctly~\cite{constraintPrinciples}: \\
\begin{equation*}
\frac{
    \begin{array}[b]{r}
      SEND \\
      + MORE
    \end{array}
  }{
    MONEY
  }
\end{equation*}
In this problem the  $\langle X, D, C \rangle$ are as follows:
\begin{verbatim}
    X:
      S, E, N, D, M, O, R, Y 
    D:
      [1..9] for S, M
      [0..9] for E, N, D, O, R, Y
    C:
      AllDifferent([S, E, N, D, M, O, R, Y])
      ExactSum([SEND, MORE], MONEY)
\end{verbatim}
There is a single solution to this CSP:
\begin{verbatim}
    S = 9, E = 5, N = 6, D = 7, M = 1, O = 0, R = 8, Y = 2
\end{verbatim}
Constraints are frequently solved using constraint solvers. A third-party constraint solving package for Python called \textit{python-constraint}. python-constraint provides a number of built-in constraint types to use such as \textit{NotInSetConstraint}, \textit{AllEqualConstraint} and \textit{ExactSumConstraint}. However, it also allows you use a \textit{FunctionConstraint} to which you provide a function defining the constraint logic. This means the constraints it can handle are endless.

\newpage
\section{Type Inference}
The main problem which is required to be solved by this project is how to statically infer the types in Python. \\
In this section we look at a number of the existing techniques to achieve this while keeping in mind the objectives described at the beginning of this report. Those were for it to return a low number of false positives, for it to statically analyse the code (not run it) and for it to be a out-of-the-box solution and for it to be reasonably fast.

\subsection{Hindley-Milner}
The Hindley-Milner algorithm was developed by Robin Milner based on the work of J. Roger Hindley. Hindley described the \textit{principal
type schema}~\cite{hindley69}, ``which is the most general polymorphic type of an expression, and showed that if a combinatorial term has a type, then it has a principal type.''~\cite{cardelli87} Milner's contribution was an extension to Hindley's \textit{principal type schema} which included the ``notion of generic and non-generic type variables, which is essential for handling declarations of polymorphic functions.''~\cite{cardelli87} Milner's work culminated in the type inference system for the ML language~\cite{milner84}. \\
The Hindley-Milner algorithm uses the operations performed on expressions to generate constraints on the types of those expressions. This is done by annotating the nodes of an expression tree with the constraints in a bottom up fashion\footnote{The Hindley-Milner algorithm can be implemented top-down, called the $\mathcal{M}$ algorithm, or bottom-up, called $\mathcal{W}$~\cite{heeren02}. However, the bottom-up version appears to be much more common.}. \\ The constraint is solved to infer a type for a term using a \textit{unification} algorithm.
Bugs can be detected by determining whether there are inconsistencies in the set of constraints.

\paragraph{Limitations}\mbox{}\\
The technique does not allow polymorphic argument to be of a different type in different locations. This is because unification requires there to be a single type for all appearances of a variable. For this reason Hindley-Milner is unable to infer a type for programs such as the following:
\begin{lstlisting}
	if (y):	
	  x = 5     
	else:
	  x = 5.0   
\end{lstlisting}
We have already seen examples such as this in previous chapters, and so the Hindley-Milner approach is not appropriate in our case.

\subsubsection{Pyty}
Developed by Jeff Ruberg~\cite{pyty}, Pyty is a bug checker which analyses annotated source code to detect errors related to the misuse of types. Pyty employs Hindley-Milner as its type inferencing algorithm.
\paragraph{Limitations}\mbox{}\\
Pyty requires annotations to the source code in a specific format. This is quite tedious and prevents from being an `out-of-the-box' solution to our problem.

\subsubsection{Palsberg and Schwartzbach Algorithm}
The Palsberg and Schwartzbach algorithm works by constructing a network of constraints where each expression in the analysed program is represented by a node in the network. The node contains the types which the expression may assume during execution. All types are initially set to be empty except from constants and literals. The constraints between the nodes are created in response to statements in the program. In the Palsberg and Schwartzbach algorithm there are two ways in which a constraint can generated: assignments and function calls. An assignment such as $x := y$ is represented by the constraint $type(x) \subset type(y)$. Function calls generate constraints between the \textit{actual} arguments used in the function call and the formal arguments in the function definition. The constraints are solved by propagating types through the constraint edges until a fixed-point in reached. \\
The algorithm was adapted to be used for object-oriented code by copying the bodies of base classes inherited into the child classes. Similarly, class definitions are duplicated at all sites at which they are constructed and method bodies are duplicated at call sites. \\
\paragraph*{Limitations}\mbox{}\\
The excessive duplication makes the algorithm impractical. In the worst case, successive expansions squared the size of the program to be analysed.


\subsection{Cartesian Product Algorithm}
The Cartesian Product Algorithm (CPA) was originally conceived by Agesen as an improvement on the Palsberg and Schwartzbach algorithm for the language Self~\cite{agesen95}. \\
The Cartesian Product Algorithm works by modelling data flow as opposed to the constraint and unification method adopted by the Hindley-Milner algorithm. This is done by building a set of possible types an expression can take. Consider the following code:
\begin{lstlisting}
	if (y):	
          x = 5     
	else:
	  x = 5.0  
\end{lstlisting}
The inferred types for $x$ would be the set $\left\{ {int, float}\right\}$, where the possible \textit{int} type is found in the \textit{then} branch and the \textit{float} type is found in the \textit{else} branch. The types from each branch are added to the set of possible types for $x$. The CPA algorithm guarantees that the type of the variable is contained within the set. \\
In order to infer the types handed to a function the cartesian product of the set of possible types for all given arguments is taken. Consider the following code:
\begin{lstlisting}
	if (y):	
	  x = 5 
	  z = "Hello world"    
	else:
	  x = 5.0 
	  z = True
	f(x, z)
\end{lstlisting}
The set of inferred types for $x$ is, as before, $\left\{ {int, float}\right\}$ and the set for $z$ is $\left\{ {str, bool}\right\}$. The possible types of the inputs to the function $f$ are: $\left\{ {int, float}\right\} \times \left\{ {str, bool}\right\} = \left\{ {(int, str), (int, bool), (float, str), (float, bool)}\right\}$, where each tuple represents the possible types of the variables given to $f$. \\
The biggest shortcoming of the Palsberg and Schwartzbach algorithm, the expansions, was remedied by the CPA algorithm. This was done by duplicating function bodies such that they contain an argument list with monomorphic types which Agesen calls templates. Each argument list generated by taking the cartesian product at calls sites is connected with constraints to the corresponding template. The types of the values returned by each template are connected to the result of the function call.
\paragraph*{Limitations}\mbox{}\\
The size of the Cartesian products grows exponentially with the number of arguments given to the function call. However the size is bounded by the number of types available. \\
The difficulty of implementation is greater than that of the Hindley-Milner algorithm which is known as being a fairly simple algorithm to implement~\cite{jones95}. \\
Taking the cartesian product of the possible types given to a function call is unnecessary if the possible types the function can take are already known. \\
While duplication has been reduced in comparison to the Palsberg and Schwartzbach algorithm, each function body is still duplicated to generate all possible templates.

\subsubsection{Starkiller}
Starkiller was designed by Michael Salib as the type inference method of a Python-to-C++ compiler~\cite{starkiller}. The algorithm used was based loosely on Agesen’s Cartesian Product Algorithm and achieves a complete type inference of Python source code.
\paragraph*{Limitations}\mbox{}\\
Unable to infer types for the dynamic constructs such as \textit{eval}, or \textit{exec}. Exceptions are unsupported. The implementation is flow-insensitive and so is not as precise as it could be. Does not handle exceptions. The types of function arguments are inferred from the call sites. The call sites are assumed to be correct.

\subsubsection{Shed Skin}
Shed Skin is a Python-to-C++ compiler developed by Mark Dufour which boasts up to a 40-fold performance increase over an older Python-to-C++ compiler, Psyco~\cite{shedskin}. Shedskin employs the Cartesian Product Algorithm (CPA) alongside iterative class-splitting. The CPA algorithm is used to allow the user to know which functions need to be defined. For instance, if Shed Skin comes across $max(1, a)$ where $a$ can be the types in the set $\{int, float\}$ the $max$ function needs to be duplicated in C++ to cover $max(int, int)$ and $max(int, float)$ which need to be defined. Dufour also needs to define classes for the types used. For data polymorphic types such as lists, the class cannot always be shared so the the classes are `split' once they can longer share the same representation of data in the equivalent C++ program.

\paragraph*{Limitations}\mbox{}\\
The programs consumed by Shed Skin are required to be implicitly statically typed. Meaning the type of a variable can not dynamically change. Shed Skin also does not support a number of Python features such as \textit{eval} and \textit{isinstance}.

\subsubsection{Localized Type Inference of Atomic Types in Python}
For his masters thesis, Brett Cannon attempted to infer the types for local, atomic (built-in) variables are inferred in an attempt to improve the performance of Python~\cite{cannonlocalizedtype}. The type inference is performed by intercepting bytecode from the interpreter and modifying it by injecting additional bytecode relating the the types of variables. The idea was the processor the interpreter is running on could utilise this information to improve performance. Cannon's work differs to Psyco in that the work is done inside of Python's compiler, rather than the interpreter.
\paragraph{Limitations}\mbox{}\\
The inference is limited to built-in types: integrals, \textit{float}, \textit{complex}, \textit{basestring}, \textit{list}, \textit{tuple} and \textit{dict} so any user-defined types are ignored. \\
The limitations involve only inferring types for local variables, meaning that the implementation is largely useless when used on programs designed with Object Oriented Programming (OOP) in mind, as noted by Cannon. While not a real limitation, Cannon's solution intercepts the compiler in order to improve performance. This is not our aim and we need not complicate things by working with bytecode.

%\subsection{Gradual Typing}


\subsection{Success Typings}
The phrase `success typings' was coined by Lindhal and Sagonas in the 2006 paper \textit{Practical Type Inference Based in Success Typings}~\cite{lindhal06}. The aim of a success typing is to fully describe all possible intended uses of a function. This description is given as type signature for a function $f$: $(\bar{\alpha}) \rightarrow \beta$, where $(\bar{\alpha})$ refers to the type of the function parameters, and $\bar{\alpha}$ is a shorthand for $\alpha_1, \alpha_2,...\alpha_n$, and $\beta$ is the type of the return value. Both types are the `largest' possible types, i.e.\ subtypes are acceptable. For instance, consider the following function as described in the Lindhal et al.\ paper for the functional language \textit{Erlang}:
\begin{lstlisting}[mathescape]
	and(true, true) $\rightarrow$ true;
	and(false, _) $\rightarrow$ false;
	and(_, false) $\rightarrow$ false;
\end{lstlisting}
where the symbol `\_' represents a \textit{don't care} option for pattern matching, meaning it will match any value for the corresponding parameter. \\
An acceptable success typing for this function, and, indeed, for any function with two arguments, would be: $(any(), any()) \rightarrow any()$ where $any()$ denotes the set of all Erlang types. Such a typing would raise no warnings about any use of the function and so can be used when no typing information can be inferred about a function. However, a more useful typing for the function in question is $(any(), any()) \rightarrow bool()$ where the return type of the function is restricted to all subtypes of $bool()$. Since we have the \textit{don't cares} any parameter paired with an instance of $false$, such as $(42, false)$, constitutes a valid use of the function. This optimistic approach avoids any possible false positives and so will never reject a well-formed program. This typing does allow for warnings to be issued as a result of type clashes in matching a value which is not a subtype of $bool()$ with the result of the function. \\
A success typing is inferred by building constraints by traversing the code and then solving them. \\
Constraints are built based on a number of derivation rules. Assume the following definitions:
$e$ is any expression which can be defined in the language under consideration, \\
$\tau$ is a type, such as a boolean or integer, $A$ represents an environment with bindings of variables of the form $\{\ldots, x \mapsto \tau_x, \ldots\}$, \\
$C$ represents nested conjunctions and disjunction of subtype constraints:
\begin{align*} 
	C \coloncolonequals (T_1 \subseteq T_2) \mid (C_1 \land \ldots \land C_n) \mid (C_1 \lor \ldots \lor C_n)
\end{align*}
\begin{align*} 
	T \coloncolonequals none() \mid any() \mid V \mid c(T_1, \ldots, T_n) \mid (T_1, \ldots, T_n) \rightarrow T'\mid T_1 \cup T_2 \mid T when C \mid P
\end{align*}
\begin{align*} 
	V \coloncolonequals \alpha, \beta, \tau
\end{align*}
\begin{align*} 
	P \coloncolonequals integer() \mid float() \mid atom() \mid pid()| 42 | foo | \ldots
\end{align*}
and the judgement $A \vdash e : \tau, C$ should be read as ``given the environment $A$ the expression $e$ has type $Sol(\tau)$ whenever $Sol$ is a solution to the constraints in C''. \\
Then one such derivation rule is the rule for a struct:
                \[
\inference*[STRUCT]{  A \vdash  e_1 : \tau_1, C_1 \ldots e_n : \tau_n, C_n}
                                        {A \vdash  c(e_1, \ldots, e_n) : c(\tau_1, \ldots, \tau_n), C_1 \land \ldots \land C_n}
                \]
The rule states that given a number of elements, each with its own type, can be grouped into a tuple structure in the environment with each individual element retaining their type. The constraints for each element are added to the environment in a conjunction. \\
$Sol$ is a mapping from type expressions and type variables to concrete types. $Sol$ is a solution to a constraint set $C$ if:
\begin{align*} 
	Sol \models T_1 \subseteq T_2 \iff none() \subset Sol(T_1) \subseteq Sol(T_2)
\end{align*}
\begin{align*} 
	Sol \models C_1 \land C_2 \iff Sol \models C_1, Sol \models  C_2
\end{align*}
\begin{align*} 
	Sol \models C_1 \lor C_2 \iff \begin{cases} Sol_1 \models C_1, Sol_2 \models C_2, \\
	                                            Sol = Sol_1 \sqcup Sol_2 \end{cases}
\end{align*}
where $Sol_1 \sqcup Sol_2$ denotes the point-wise least upper bound of the solutions. \\
Each case represents a different type of constraint which we may encounter (subtype, conjunction or disjunction). The subtype case states that a solution satisfies a subtype constraint if the mapping satisfies the subtype constraint and neither of its constituents is \textit{none()}. The conjunction case states that the solution must satisfy all conjunctive parts. The disjunction case that the solution is the point-wise least upper bound of all disjuncts.

\subsection{Soft Typing}
Cartwright and Fagan extended the Hindley-Milner $\mathcal{W}$ algorithm to introduce soft typing~\cite{cartwright91}. The aim of soft typing is not to reject a program for which static type checking fails but to ``transform arbitrary programs to equivalent programs that type check.'' Soft typing works by inserting run-time checks, resulting from ``narrowers,'' when a program fails to statically type a program, i.e.\ when unification in $\mathcal{W}$ fails. Narrowers are type casts which blindly convert from the current type to the destination type. Conversion errors are caught by the run-time checks. \\
Soft typing requires a program to be run in order to notify the programmer about errors. Our aim is to create a static debugger and so our aims are incompatible with soft typing.

\subsection{Aggressive Type Inference}
Aggressive type inference (ATI) is a technique developed by John Aycock~\cite{aggressiveType} which follows the idea that:
\begin{quote}
	\emph{``Giving people a dynamically-typed language does not mean that they write dynamically-typed programs.''}
\end{quote}
Aycock backs up this hypothesis by citing a study~\cite{typeInferenceIcon} which reveals that around 80\% of operators in a set of \textit{Icon} programs maintain the same type throughout their lifetime. \\
He exploits this by using a flow-insensitive method and does not use union types. Meaning the algorithm does not look through all routes to determine all possible types for a variable and only labels a variable with a single type, not a union of multiple types. The algorithm works by iteratively analysing the code to infer the types of variables and by propagating the types on each iteration.
\paragraph{Limitations}\mbox{}\\
The limitations of Aycock's approach are quite clear: the types involved in dynamic behaviour are not reliably extracted. How much of an issue this poses is up for debate;
A study on this, more recent and relevant to our interests than the \textit{Icon} analysis put forward by Aycock, has been conducted by Alex Holkner and James Harland~\cite{evaluatingDynamicBehaviour}. This study details the evaluation of twenty four open source Python systems. Their results argue that dynamic features are actually widely used. For instance, they find that all systems studied employ dynamic code execution. Holkner and Harland concede that their study is small in comparison to the amount of Python code available, however if their results are to be extrapolated then Aycock's assumption is not so reasonable.

\subsection{RPython}
RPython is an intermediate language, a subset of Python which is entirely statically typed and which acts as a link in the PyPy toolchain. PyPy's goal is to develop a Just-In-Time (JIT) compiler for Python. PyPy's interpreter is written in RPython which removes dynamic features in order to reduce the complexity of type inference.
\paragraph{Limitations}\mbox{}\\
The major limitation of PyPy is the use of RPython. One feature of RPython is that it does not allow variables to change their type.

\subsection{Related Work}
To the best of my knowledge, there is currently no bug finder for type errors in Python which does not return any false positives. The most active debuggers at the time of writing are Pylint and and PyChecker.
%\subsubsection{Psyco}
%Psyco is a just-in-time (JIT) compiler for Python, designed to improve performance~\cite{psyco}. Psyco replaces the main interpreter loop of Python in order to examine the bytecode and, where appropriate, emits specialized bytecode in its place. CITATION NEEDED
%\paragraph*{Limitations}\mbox{}\\
%Psyco only attempts to infer locally defined \textit{ints} and \textit{strings} and pays little interest to any other types.

\subsubsection{Pylint}
Pylint is an error checking tool for Python which statically analyses Python source code to look for errors, including type errors, and to assess the coding style. Pylint is a static analyser and so it looks for errors without importing/running the source code. \\
Documentation on Pylint is almost non-existent and the source code is also quite difficult to understand so, unfortunately, we currently do not understand the type inference algorithm of Pylint.
\paragraph{Limitations}\mbox{}\\
Can often return a lot of false positives and offers a large number of command-line options in an attempt to allow users to manually suppress them.

\subsubsection{PyChecker}
PyChecker is an bug checker for Python which checks for type errors among a host of other errors. PyChecker is similar to Pylint except it does not checker the coding style of the source program. PyChecker also differs in that it needs to runs the code in order to analyse it.
\paragraph{Limitations}\mbox{}\\
The type inference is quite limited. PyChecker focuses on 'softer' type errors, such as whether a variable exists and whether self is the first method argument. \\
PyChecker can return spurious errors and warnings. PyChecker imports the code it is analysing which can have undesirable side effects, such as execute a database query in the code.

\subsubsection{PySonar}
PySonar was developed by Yin Wang while an intern at Google between 2009 and 2010 and was intended for the internal use within Google's Grok project~\cite{pySonar}. PySonar was primarily developed as a tool to allow the user to better search and understand Python code. It includes a type inferer in order for the types of variables to be displayed in a tooltip. It also includes an indexer to allow quick search through code. PySonar uses abstract interpretation to infer the types of the variables. PySonar claims to be able to resolve the names of 97\% of the Python standard library.
\paragraph{Limitations}\mbox{}\\
PySonar is focused on indexing the code it analyses and so it does not report any possible type errors. The program focuses mainly on a less dynamic subset of Python which is `easier' to analyse.

\subsubsection{Pyntch}
Created by Yusuke Shinyama, Pyntch uses type inference in Python in order to find bugs~\cite{pyntch}. The method used is `type flow analysis', which is a form of a data flow analysis where the types are tracked as they flow from variable to variable. \\
Project activity has ceased since 2009.
\paragraph{Limitations}\mbox{}\\
Pyntch completely disregards execution order. In the following example given by the author:
\begin{lstlisting}[mathescape]
	x = 1
	x = 'a'
\end{lstlisting}
The variable \textit{x} will always have the type $\{int, string\}$ after analysing the second statement. \\
Pyntch is unable to infer types in code which use the following functions: globals, locals, getattr, setattr, eval, compile or exec. \\
As well as the inaccuracies listed, the Pyntch author states that ``sometimes Pyntch brings a lot of false positives in its result, which need to be further examined by human programmers.''

%\subsection{Javascript}
%Javascript is a dynamically typed scripting language, similar to Python. \\
%Abstract interpretation lattice \\


\subsubsection{Ruby}
Ruby is a dynamically typed scripting language, similar to Python. \\
Furr et al. developed Diamondback Ruby (DRuby)~\cite{furr09} in order to discover type errors. DRuby works by using type annotations of library functions in order to generate constraints to infer the types for user defined functions. \\
DRuby is not sound as it accepts programs which are dynamically incorrect. DRuby also reports false positives. \\
An extension to Diamondback Ruby, $\mathcal{P}$Ruby, was created in order to handle difficult dynamic language constructs such as the \textit{eval} method which converts a string into executable program code.~\cite{pRuby} This is done by instrumenting the code such that, when the program is run, all uses of the dynamic constructs are recorded. This allows a \textit{profile} to be built which fully describes how they were used. With this profile the dynamic code can be inserted into the program in place of the dynamic constructs. The modified program can then be statically analysed just like any other. Furr et al. use DRuby for the analysis.

\newpage
\section{Implementation}
This project was built on top of the work by Edward K. Ream's \textit{stc}~\footnote{\url{https://code.launchpad.net/~edreamleo/python-static-type-checking/trunk} Revision \#448 was used for this project.}. The primary contribution taken from stc, which was left largely unchanged, was the traversers which are used to navigate the the abstract syntax tree.

\subsection{Generating the Control Flow Graph}
Due to the limitations of the CFG generators for Python as previously described, the decision was made to create our own. It was felt that no current generator provided a platform to extract a CFG containing the necessary information about each statement which wouldn't require time consuming modification. By the time the decision was taken to implement a CFG generator the implementation of the type inferencer was well underway. The benefit of writing our own generator was that it could be written in a manner which will make it easy to integrate with currently written type inferencer. \\

\subsubsection{Ifs and Elses}


\subsubsection{Breaks and Continues} 
Taking inspiration from the PyPy implementation, a stack was implemented on which labels are pushed (\textit{F\_BLOCK\_LOOP}, \textit{F\_BLOCK\_EXCEPT}, \textit{F\_BLOCK\_FINALLY}, \textit{F\_BLOCK\_FINALLY\_END}) alongside their corresponding nodes. Once we encounter a break or continue statement we cycle through the labels until we encounter a \textit{F\_BLOCK\_LOOP} label. Then for a break statement we add an exit for the current block to the loop's next block and to the loop block itself for a continue statement.

\subsubsection{Try, Excepts and Finallys} 

\subsection{SSA Form}
The implementation of SSA renaming was performed precisely as described in the background section. A few additional allowances were required for the system to function correctly. These will be explained here.

\subsubsection{Global and Local Variables}
Consider the following snippet of Python code:
\begin{lstlisting}
    class C():
      def f(self):
        self.x = 5
     
      def g(self):
        self.x = 5.0         
        
      def h(self):
        a + self.x 
\end{lstlisting}
The references to $self.x$ refer to the same variable. The principles of SSA naming state that a variable should only be assigned to once. But which $x$ should be labelled $x_1$ and which should be labelled $x_2$? Or, rather, which of the assignments to $x$ in function \textit{f} and function \textit{g} will be called first? Without any analysis of the call sites or typical run-time behaviour it is impossible to determine this statically. A similar problem arises when we attempt to decide which reference to give to the instance of \textit{self.x} in function \textit{h}. Without knowledge of the order the functions are called (if a consistent ordering even exists) we cannot predict which is the correct label. For this reason SSA naming is only performed on local variables.


\subsection{Type Inference}




\subsubsection{Inferring the Types of Simple Assignments}
All changes to the types of variables involve assignment. For each assignment the variable on the left-hand side (LHS) assumes all of the types which the right-hand side (RHS) can possibly have. The following shows a number of ways in which this can be done.
\begin{lstlisting}
	x = 5
	x = "Hi"
	x = f()
\end{lstlisting}
Assignments with a simple numeric or string value can be inferred very easily and we can assign the variable a single possible type with complete confidence. If the RHS is a function then we assign all of the types the function can possibly return.

\subsubsection{Inferring the Types of Binary Operations}

\subsubsection{Inferring the Types of Unary Assignments}

\subsubsection{Inferring the Types of Augmenting Assignments}

\subsubsection{Inferring the Types in List/Tuple Assignment}
% x = [5, 2]
% [x, y] = [5, 2]

\subsubsection{Inferring the Types in Del statements}
The \textit{Del} statement is used to remove an identifier binding. If the target of the Del statement is a variable then the type of that variable is set to \textit{None\_Type}. Otherwise, if the target is an element in a list or dict then that single element is removed. In the case of a variable we can change the set of types assigned to this variable. However, it is more complicated in the case the target is an element of a list or dict. In theory we could simply remove the type(s) associated with that element from the types contained in the list/dict but this would only be correct if the element being removed was the \textit{only} element in the list/dict with that type. This may prove difficult to track. For instance, consider the following trivial example:
\begin{lstlisting}[mathescape]
    from random import randomint
    l = ["Hi", 5, 5.0]
    del l[randint(0, 2)]
\end{lstlisting}
This example will delete a random element from the list. It impossible to statically predict which element, and therefore type, that will be removed. A similar problem arises when a dynamic number of elements is added, such as when looping over a file and adding elements found until the end of the file is reached. In this case we cannot determine how many elements need to removed before we can safely remove the type from the set of types contained in the list/dict. \\
For these reasons we do not change the set of types contained in the list/dict after a \textit{del} operation.

\subsubsection{Inferring the Types in For/While Loops}

The following shows a `raw' while loop and the same while loop in SSA form:
\begin{lstlisting}[mathescape]
    # Raw form
    x = 5
    while (p):
      y = x
      x = "Hi"
	
    # SSA form
    x1 = 5
    while (p):
      x2 = $\phi$(x1, x3)
      y1 = x2
      x3 = "Hi"
    x4 = $\phi$(x1, x3)
    y2 = $\phi$(y1, None)
\end{lstlisting}
A problem raised by this is that the $\phi$ function at the beginning of the loop depends on the types which can not be determined until the end of the loop body. In between there may be other variables which use the result of the $\phi$ function in their own assignment, like $y1$ above. To overcome this we use a \textit{Awaiting\_Type} value which is assigned to any variable which is awaiting the type of another variable, the \textit{waiter} along with the name of the variable they are waiting for, the \textit{waitee}. In the case above we have $x2$ waiting for $x3$ and $y1$ waiting for $x2$. When a waitee is assigned its types then attempts are made to type all of that variable's waiters. If it is found they also need to wait for another variable then the same process occurs again otherwise they are successfully typed. Currently this approach collapses if there is a circular assignment involving a waiter and waitee, e.g.\ $x2 = x1 + 1$ where $x1$ which can cause the waiter of each to be each other. Currently if this circular assignment is detected then both variables are assigned the Any\_Type.


\subsubsection{Inferring the Possible Types of Function Arguments}
There are number of ways we can go about inferring the types of function arguments. We could use either a \textit{top-down} approach or a \textit{bottom-up} approach. A top-down approach involves finding all of the calls to a function and determining the types the function accepts by the inferring the types of values given. On the other hand a bottom-up approach involves determining the types of arguments solely by how they are used within the function body. Initially our approach was to use the bottom-up approach. It was felt that more was to be gained using this approach since we would be able to detect errors caused by incorrect types being passed to a function. However it is important to note that useful information can be extracted from the calls. There is a possibility of using this information when we are unable to infer the types of the parameters using the function body in isolation. \\
To do this we will generate a number of constraints and attempt to solve them. In order to solve the constraints we will make use of a pre-existing constraint solver for Python, \textit{python-constraint}~\footnote{\url{http://labix.org/python-constraint}}. When our generated constraints cannot be solved, we resort to labelling the parameter as having any possible type (AnyType / Top).
It is important to do this before we attempt to infer the return types of a function as it is likely that the possible return types will depend upon the types of the function arguments. \\\\
\textbf{Constraint Generation} \\
Consider the following two functions:
\begin{lstlisting}[mathescape]
	def f(x, y):
	  return x + y
		
	def g(x, y):
	  if (p1):
	    return x + y
\end{lstlisting}
Both functions apply the $+$ operator to the parameters. However, due to the \textit{if} statement the constraint this imposes on the types they can take is quite different. In function \textit{f} the operation is unconditional and so we know that both parameters are required to be of a type (or a sub-type of a type) which can used in this operation. On the other hand, in the function \textit{g} this statement may not be executed in which case we can see that no type errors can occur. This leads us to conclude that we must take the context of the statement into account before we issue a constraint.
\\\\
\textbf{Constraint Solving} \\
Our constraint solver returns all possible sets which satisfy the constraints we feed into it. We are interested in \textit{all} of the possible types a parameter can legally take. Because of this we take the largest set returned for each parameter.

\subsubsection{Extracting Information From Call Sites}

\subsubsection{Inferring the Possible Return Types of a Function}
To do this we rely on the $\phi$ function as described in the SSA section. We simply take the union of all of the variables passed. Consider the following, already transformed, example:
\begin{lstlisting}[mathescape]
	def f():
	  if ($p_1$):
	    $r_1$ = 5
	  if ($p_2$):
	    $r_2$ = "Hi"
	  $r_3$ = 5.0
	  $r_4$ = $\phi$($r_1$, $r_2$, $r_3$)
\end{lstlisting}
The determined possible returns types are $r_1 \cup r_2 \cup r_3 = \{Int\} \cup \{String\} \cup \{Float\} = \{Int, Float, String\}$. \\
There is a the possibility of a relationship between the types of the parameters and the return types, e.g.\ a string is always returned if an integer is given. While this addition would improve the accuracy of our type inference, it would be complex to implement.

\subsubsection{Inferring the Types Involving Recursive Functions}


\subsubsection{Inferring Context}
Unlike many static languages such as Java and C++, Python is heavily dependent on context. This may lead to the same function and class having very different values at different times in the program. Consider the following class:
\begin{lstlisting}[mathescape]
	class C():
		def __init__(self):
			self.x = 3
			
		def f(self):
			self.x = 3.0
\end{lstlisting}

\subsubsection{Inferring the Classes}
In statically typed languages such as Java and C++ the global variables are required to be specifically defined outside of the function and in the main body of the program. In Python this is not required. The global variables which can be accessed outside of a class can be declared in a function within that class, and even outside of the class entirely. If a variable has been declared inside of a function, then the function is required to be called before the variable is referenced. An example of this is as follows:
\begin{lstlisting}[mathescape]
	class C():
	  def f():
	    self.x = 5
		
	  def g():
	    self.x = "hi"
	# Using the class C
	c = C()
	print(c.x)    # Error
	c.f()
	print(c.x)    # Okay - prints 5
\end{lstlisting}
You may also notice that the global variable held by C can be different types - \textit{int} or \textit{float} depending on which of the functions \textit{f} and \textit{g} was called last. To infer the types of these variables we can use a few different methods.

\paragraph{Method One: Any Possible Type at Any Time}\mbox{}\\
Whilst analysing the functions of the class we can keep track of all of the possible types of each global variable. We do this on a function-by-function basis. So once we have analysed function \textit{f} we believe that the variable \textit{x} can be the set of types $\left\{ {int}\right\}$. We update this to $\left\{ {int, float}\right\}$ after the analysis of the function \textit{g}. Once the entire class has been analysed and the variable has been accessed we return all of the possible types the variable can be. This method is not very accurate, and does not take into account the changes that the function calls obviously make the object.

\paragraph{Method Two: Treat Function Calls as Object Modifiers}\mbox{}\\
Whilst analysing the functions of a class, instead of recording all of the types a variable can take we can tag the function with the variable modifications it makes. So for the example given above we would tag for the function \textit{f} as modifying the variable \textit{x} to $\left\{ {int}\right\}$ and function \textit{g} to $\left\{ {float}\right\}$. However to take advantage of this information we are required to manipulate the calling code somewhat. If we are stating that the functions change the state of the object then we need to explicitly indicate this as we did with `normal' variables with SSA naming. For example, consider the calling code for the class C example we gave above. We would edit this to be the following:
\begin{lstlisting}[mathescape]
	# Using the class C
	c1 = C()
	print(c1.x)    # Error
	c2 = c1.f()
	print(c2.x)    # Okay - prints 5
\end{lstlisting}
We assume that the function creates a special kind of assignment to the object with the old object information plus the changes to the global variables made by the function. If the function returns a result and is already part of a regular assignment then we would just have two assignments, the original assignment and the new special object replacement kind. \\
This method is much more accurate than the first as we keep track of how a object instance grows and changes with each function call made upon it. However the price we pay for this accuracy is a much complex implementation process.

\paragraph{Small Improvement: Analyse the \textit{\_\_init\_\_} Function First}\mbox{}\\
The equivalent of a Java/C++ constructor in Python is the \textit{\_\_init\_\_} function. While Python in no way forces you to declare your \textit{self} variables in the \_\_init\_\_ function, it makes sense to do so and we can reasonably assume that large percentage is declared there. The advantage of analysing this function before the others is that if a global variable is referenced (not assigned to) in a function then to acquire the most accurate typing of that function we want to already having typing information available for that variable. To do this we simply look for the \_\_init\_\_ function in the list of the functions contained in the class and move it to the top of the list if it is found.

\paragraph{`Magic' Functions}\mbox{}\\
Python has a large number of special functions which can be implemented by the programmer which will then be used in a unorthodox way. All of these functions are characterised by having a double leading and trailing underscores. The most frequently used of these is \textit{\_\_init\_\_}

\subsubsection{Inheritance}\mbox{}\\
In Python inheritance works by inserting the name of the base class within the parenthesis of the class declaration. Multiple inheritance is supported by separating the base classes with commas. The multiple inheritance by looking through the base classes, in order, until the referenced variable/function is found. Therefore preference is given to the base classes listed first.
\begin{lstlisting}[mathescape]
	class C():
	  def f():
	    self.x = 5
		
	  def g():
	    self.x = "hi"

	class D(C):
	  def f():
	    self.y = 5
		
	  def h():
	    self.y = "hi"
\end{lstlisting}
In the example above the class \textit{D} inherits from the base class \textit{C}. The function \textit{g} is inherited along with the variable \textit{x} (if we are using Method One.) However the function \textit{f} is overridden by \textit{C}. Initially the function is given the to \textit{C} but is replaced by its own version once our analysis reaches the function.

\subsubsection{Inferring types involved in \textit{with} statements}
When dealing with objects which need to be built up before their use and clean up after they have been used, such as file manipulation, engineers using Python had to follow a process similar to the following in the past:
\begin{lstlisting}[mathescape]
	# Set up object
	file = open("file.txt")
	try:
		# Do something
		data = file.read()
	finally:
		# Clean up
		file.close()
\end{lstlisting}
The code ensures the the object is constructed before use, due to flow restrictions, and destroyed after being used since all paths exiting the \textit{try} must lead to the finally. Python 2.5 introduced the \textit{with} keyword to make this code cleaner. Using \textit{with} a example on a file becomes:
\begin{lstlisting}[mathescape]
	with open("file.txt") as file:
		data = file.read()
\end{lstlisting}
\textit{with} works by calling the \textit{\_\_enter\_\_} function on the object provided immediately after the \textit{with} keyword (\textit{open} returns a file) and calling the \textit{\_\_exit\_\_} function when the body has exited. An engineer can build their class to work with the \textit{with} keyword by implementing these functions with their construction and destruction code. For example:
\begin{lstlisting}[mathescape]
	class Example():
		def __enter__(self):
			pass
			
		def __exit__(self, type, value, trace):
			pass
			
		def do_something(self):
			# Do something
			
	with Example() as ex:
		ex.do_something()
\end{lstlisting}
The \textit{type}, \textit{value} and \textit{trace} parameters provide information which can used to handle exceptions. \\
We can handle the \textit{with} keyword by de-sugaring it back into its equivalent try-finally. The set-up code will involve assignment to the specified variable and a call to the \textit{\_\_enter\_\_} function. The finally block will simply consist of a call the \textit{\_\_exit\_\_} function. Our transformed \textit{with} using the \textit{Example} class will look like so:
\begin{lstlisting}[mathescape]
	ex = Example()
	ex.__enter__()
	try:
		ex.do_something()
	finally:
		ex.__exit__(p1, p2, p3)
\end{lstlisting}
The main difficulty involved with this transformation is simulating the variables passed to the \textit{\_\_exit\_\_} function. The simplest way to deal with this is to pass temporary variable which have an \textit{Any\_Type}.
\bibliography{mybib}{}
\bibliographystyle{plain}

\subsubsection{Python Standard Library}
One possible reason for Python's popularity is its extensive standard library. 3rd party library are also popular, with millions of downloads (source). There are two ways these can used. Included it in the project directory, or by installing it on the machine the code is running on.
\newpage

\end{document}


